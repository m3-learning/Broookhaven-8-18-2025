{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxrwNCW3d_W5"
      },
      "source": [
        "# Unsupervised Spectral Unmixing with Autoencoders\n",
        "\n",
        "By Joshua C. Agar, Shuyu Qin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQlRAd-TeGsP"
      },
      "source": [
        "- There are many times where you want to extract imporant features from high-dimensional data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aor3TB9deGsP"
      },
      "source": [
        "- In essence, the goal is to compress data to some lower latent space where you can extract information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Du1zN74ev1K"
      },
      "source": [
        "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/3-swissroll-unfolded.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb7JkH3jffXB"
      },
      "source": [
        "## Autoencoder\n",
        "\n",
        "![imag](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/Autoencoder.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hERoZydoeGsQ"
      },
      "source": [
        "- **Encoder** - Neural network that deconstructs the data into the most important statistical components\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am7CDrXteGsQ"
      },
      "source": [
        "- **Embedding Layer(s)** - One or many layers were information is extracted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2imKr5WeGsQ"
      },
      "source": [
        "- **Decoder** - Neural network that translates the latent space to original dimensionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tan6uQ68eGsQ"
      },
      "source": [
        "### Mathematical Objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfM709N6eGsR"
      },
      "source": [
        "- Minimize the reconstruction loss based on some metric.\n",
        "  - Mean squared error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5c7-PKXeGsR"
      },
      "source": [
        "- Good at avoiding influence of anomalies\n",
        "  - Mean absolute error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVnJFuiFeGsR"
      },
      "source": [
        "- Good at capturing details within spectra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C25vLbxeGsR"
      },
      "source": [
        "### Optimizers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIzb2H5WeGsR"
      },
      "source": [
        "- Standard optimizers like ADAM tend to be sufficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qO9j5KKeGsR"
      },
      "source": [
        "- Can use more complex optimizers 2nd order, adhessian to optimize small models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_2ZzR6veGsR"
      },
      "source": [
        "### Practical Objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtyHEghHeGsR"
      },
      "source": [
        "- Create an autoencoder that has performant reconstruction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hag5Ig9PeGsR"
      },
      "source": [
        "- Create a low-dimensional and interpretable latent space\n",
        "  - Reduce the dimensionality\n",
        "  - Impose non-negativity contraints\n",
        "  - Impose regularization\n",
        "  - Impose sparsity\n",
        "  - Impose constraints on the shape of the latent distribution\n",
        "  - Impose soft-constraints that favor disentanglement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn9OL6IleGsR"
      },
      "source": [
        "- Create a latent trajectory that is suitable for generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oWjlBBJzs73"
      },
      "source": [
        "# Imports Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmQzQMigeGsR",
        "outputId": "0596e982-a046-41f2-e9e7-8238d98b50d7",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# installs the tutorial package\n",
        "!pip install m3_learning --no-deps\n",
        "!pip install scikit-learn\n",
        "!pip install wget\n",
        "!pip install hyperspy\n",
        "# !pip install py-cpuinfo\n",
        "# !pip install opencv-python\n",
        "# !pip install pycroscopy\n",
        "# !pip install tensorflow\n",
        "# !pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0VKiyka604-",
        "outputId": "70b0e0b9-3489-4840-c694-d100ffabaa0f",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from m3_learning.util.code import print_code\n",
        "\n",
        "\n",
        "from m3_learning.viz.nn import embeddings, latent_generator\n",
        "from m3_learning.nn.random import random_seed\n",
        "from m3_learning.viz.style import set_style\n",
        "from m3_learning.nn.time_series_nn.nn_util import Train, transform_nn, loss_function\n",
        "from m3_learning.viz.layout import layout_fig, embedding_maps\n",
        "from m3_learning.util.data_generators import generate_data\n",
        "\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "set_style(\"default\")\n",
        "random_seed(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXjwNNaSz5MS"
      },
      "source": [
        "# Generating Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFU7I6I2eGsS"
      },
      "source": [
        "- We want to generate a hyperspectral image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6lZudBgeGsS"
      },
      "source": [
        "- This can be done by taking the RGB values of an image and using them as parameters for a function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJLKait50MP6"
      },
      "source": [
        "## Loads and image of my dog Nala\n",
        "\n",
        "- Painting by _Irene Dogmatic_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG4YZi2tfeSi",
        "tags": [
          "skip-execuation"
        ]
      },
      "outputs": [],
      "source": [
        "# Loads dog image\n",
        "image = io.imread(\n",
        "    \"https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/nala.jpg?raw=true\"\n",
        ")\n",
        "\n",
        "# Crops dog image\n",
        "image = image[200:1900:20, 100:1500:20] / 255\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUpSmdfP0Ysv"
      },
      "source": [
        "## Displays the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ud8Peh1Sd9CJ",
        "outputId": "78b5c67a-6c82-4fbe-fca7-c961c358a301",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# Plots dog image\n",
        "plt.imshow(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x-NFM-D0hpm"
      },
      "source": [
        "## Generating some data based on the image\n",
        "\n",
        "### Define a non-linear function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EmkJWMFZ2lP"
      },
      "source": [
        "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/generated.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDjT0mgu8BbE",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "def non_linear_fn(t, x, y, z):\n",
        "    tanh = nn.Tanh()\n",
        "    selu = nn.SELU()\n",
        "    sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # returns a function from variables\n",
        "    return (\n",
        "        tanh(torch.tensor(20 * (t - 2 * (x - 0.5))))\n",
        "        + selu(torch.tensor((t - 2 * (y - 0.5))))\n",
        "        + sigmoid(torch.tensor(-20 * (t - (z - 0.5))))\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp5Mgyj2eGsT",
        "outputId": "106bbafa-791f-4f98-9f26-a438549b089b",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "print_code(generate_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgyhh4WH048G",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# generates a hyperspectral image\n",
        "dog_data = generate_data(image.reshape(-1, 3),\n",
        "                         length=10, function=non_linear_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDoZk7t178n_",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# Conducts a test train split.\n",
        "# because we are training an autoencoder x and y are the same\n",
        "X_train, X_test, _, _ = train_test_split(\n",
        "    dog_data, dog_data, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh-D-oH615jI"
      },
      "source": [
        "## Plots the generated data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "fgblwFiWf0b0",
        "outputId": "8f51dc79-3237-4393-a31b-9f98b5c24644",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "fig, ax = layout_fig(6, mod=3, figsize=(10, 5))\n",
        "\n",
        "ax = ax.ravel()\n",
        "\n",
        "cmap = plt.cm.viridis\n",
        "\n",
        "for i, ax in enumerate(ax):\n",
        "    # for the first three plots we plot the image\n",
        "    if i < 3:\n",
        "        img = np.zeros(image.shape)\n",
        "        img[:, :, i] = image[:, :, i]\n",
        "        ax.imshow(img)\n",
        "    else:\n",
        "        # for the last three plots we plot the hyperspectral image\n",
        "        values = np.zeros((5, 3))\n",
        "\n",
        "        # generates 5 linearly spaced values between 0 and 1\n",
        "        values[:, i - 3] = np.linspace(0, 1, 5)\n",
        "\n",
        "        # generates the spectra\n",
        "        y_data = generate_data(values, length=10)\n",
        "\n",
        "        for j in range(y_data.shape[0]):\n",
        "\n",
        "            # computes the colormap for each spectra based on the value\n",
        "            color = cmap((j + 1) / y_data.shape[0])\n",
        "\n",
        "            # plots the data\n",
        "            ax.plot(y_data[j], c=color)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI_jGvwM9Qz1"
      },
      "source": [
        "## Building a Simple Autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QkBuOi98j6K"
      },
      "source": [
        "### Defines the encoder and the decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cMY_3I9mJ0X",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# sets the number of latent dimensions for the autoencoder\n",
        "latent_dim = 12\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encoder class for the autoencoder\"\"\"\n",
        "    def __init__(self, latent_dim=12):\n",
        "        self.latent_dim = latent_dim\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dense_1 = nn.Linear(10, self.latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # single dense layer in the model\n",
        "        x = self.dense_1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Decoder class for the autoencoder\"\"\"\n",
        "    def __init__(self, latent_dim=12):\n",
        "        self.latent_dim = latent_dim\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dense_1 = nn.Linear(self.latent_dim, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # single dense layer in the decoder\n",
        "        x = self.dense_1(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfc1_DKg89Il"
      },
      "source": [
        "### Builds the autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxBAeRAjn3j3",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder class that combines the encoder and decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encode\n",
        "        embedding = self.encoder(x)\n",
        "        # decode\n",
        "        predicted = self.decoder(embedding)\n",
        "\n",
        "        return predicted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoxAH5zO9E3-"
      },
      "source": [
        "### Instantiates the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cNWSsKsoYSi",
        "outputId": "cc9fd424-0a47-4027-c6a1-3308b1e61bc3",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "import cpuinfo\n",
        "\n",
        "cpudata = cpuinfo.get_cpu_info()[\"brand_raw\"]\n",
        "cpuname = cpudata.split(\" \")[1]\n",
        "\n",
        "# choose a device based on your system\n",
        "if cpuname == \"M1\":\n",
        "    device = \"mps\"\n",
        "elif torch.cuda.device_count():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"You are running on a {device}\")\n",
        "\n",
        "# builds the encode, decoder, and autoencoder\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km3uI5CH8huM",
        "outputId": "1424deba-e8e9-4114-cfbe-8b7914a7013c",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# prints the model structure\n",
        "\n",
        "try:\n",
        "    summary(model, ((X_train.shape[1:])))\n",
        "except:\n",
        "    model_cpu = copy.deepcopy(model).to(\"cpu\")\n",
        "    summary(model_cpu, ((X_train.shape[1:])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j25InFsO9ltY"
      },
      "source": [
        "- Encoder with 12 latent dimensions\n",
        "- Decoder with with size 10 --> same as orignal spectral length\n",
        "- Autoencoder considers time by saying each timestep is its own fully-uncorrelated sample\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ONHBOPeGsa"
      },
      "source": [
        "### Builds the dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o4khQII-uL_",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "# builds a dataloader\n",
        "train_iterator = torch.utils.data.DataLoader(\n",
        "    X_train, batch_size=256, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3w3PIkveGsa"
      },
      "source": [
        "### Trains the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PteI7sUjeGsa",
        "outputId": "070b58ea-9305-457b-8fa8-20ccb13530df",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "print_code(Train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aRHZYt2-05O",
        "outputId": "e7eba1a1-bafa-4568-b65e-70b3393da67b",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# fixes the seed\n",
        "random_seed(seed=42)\n",
        "\n",
        "# trains the model\n",
        "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbhVbE-EeGsb"
      },
      "source": [
        "### Evaluates the model after training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNEVKlCyeGsb",
        "outputId": "3eea05eb-82d6-40b0-82ad-d0be60726661",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "print_code(transform_nn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkUSAm6bD8gb",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# evaluates the model\n",
        "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "x15LcmeSEXtM",
        "outputId": "582aad31-55e4-471b-8ff2-7b006a3b7d4b",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# computes the embeddings\n",
        "embeddings(encode, shape_=image.shape[0:2], figsize=(15, 5), clim=(-2, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvcvX4PMEpnW"
      },
      "source": [
        "- This is clearly an overcomplete example since we are learning 10 timesteps with 12 latent variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDUFWLs6-dkF"
      },
      "source": [
        "- We know that we only have 3 intrinsic latent variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl8BkctFm6vC"
      },
      "source": [
        "## Model with 3 latent variables\n",
        "\n",
        "### Instantiates the model (3 latent variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdCRnufQm6vC",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# rebuilds the model with 3 latent dimensions\n",
        "encoder = Encoder(latent_dim=3).to(device)\n",
        "decoder = Decoder(latent_dim=3).to(device)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGBtA4Qdm6vC",
        "outputId": "4d70b8c8-c823-4693-ca51-9ea26a97c38f",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# prints the summary of the model\n",
        "summary(model, ((X_train.shape[1:])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vijFKSkSm6vD"
      },
      "source": [
        "- Encoder with 3 latent dimensions\n",
        "- Decoder with with size 10 --> same as orignal spectral length\n",
        "- Autoencoder considers time by saying each timestep is its own fully-uncorrelated sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmyDq0a-m6vD",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "train_iterator = torch.utils.data.DataLoader(\n",
        "    X_train, batch_size=256, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-9UkhHOeGsb"
      },
      "source": [
        "### Trains the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EwGfIV4m6vD",
        "outputId": "aa187b06-15d4-4f85-9b9c-bc161a5427d6",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "random_seed(seed=42)\n",
        "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUd6n2n4m6vD",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "NMa1SoDym6vD",
        "outputId": "a72c78a9-a3c7-49be-e8e9-bc8a9207e1f2",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "embeddings(encode, shape_=image.shape[0:2], figsize=(10, 5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwA-Tvkmm6vD"
      },
      "source": [
        "- This is clearly an overcomplete example since we are learning 10 timesteps with 12 latent variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyxCzFQpR8Qf"
      },
      "source": [
        "### Generator\n",
        "\n",
        "- Now we want to see how the spectra changes as we traverse the latent space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "0N1pohL3pFSX",
        "outputId": "679895a3-4cf0-4b0a-daeb-520646233668",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
        "                 figsize=(10, 5), divider_=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV0CTdFaqtEY"
      },
      "source": [
        "## Recurrent Neural Network Autoencoders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiOhstXZeGsc"
      },
      "source": [
        "- The above example did not consider the temporal information in the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbwtmvKzeGsc"
      },
      "source": [
        "- This can be improved by using a recurrent neural network that processes each time step sequentially.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTRY-CykeGsc"
      },
      "source": [
        "- To add an understanding about the short and long term information in the data you can add memory and forget logic as a learnable parameter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YVtX9RReGsc"
      },
      "source": [
        "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/Autoencoder_Med.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhTv9qVIaSKZ"
      },
      "source": [
        "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/LSTM%20Node.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVpf_LM5eGsc"
      },
      "source": [
        "### Builds the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpPgTyg5qsBj",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "latent_dim = 12\n",
        "\n",
        "# encoder with LSTM\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=12):\n",
        "        self.latent_dim = latent_dim\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(1, 12, batch_first=True, bidirectional=True)\n",
        "        self.embedding = nn.Linear(24, self.latent_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (_, __) = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.embedding(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=12):\n",
        "        self.latent_dim = latent_dim\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(self.latent_dim, 12,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.tdd = nn.Conv1d(24, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[:, :, None]\n",
        "        x = x.transpose(1, 2)\n",
        "        x = x.repeat([1, 10, 1])\n",
        "        x, (_, __) = self.lstm(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.tdd(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxQRoBpkmsMG",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DywwBICleGsc"
      },
      "source": [
        "### Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kgrRjyL6IQe",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "train_iterator = torch.utils.data.DataLoader(\n",
        "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb8PpA9ueGsc"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pI6_sXa6IQf",
        "outputId": "06837339-8157-4fc5-cea8-472aba4808ee",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "random_seed(seed=42)\n",
        "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmOG4K36eGsc"
      },
      "source": [
        "### Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9ko8uLpARY",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "CpemVGfyDhar",
        "outputId": "7ec66619-6f8a-43b1-e77b-f73b12cae12a",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "embeddings(encode, shape_=image.shape[0:2], figsize=(15, 5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBIIsSGPGdRg"
      },
      "source": [
        "- This does not really mean too much because the latent variables are all competing with one another\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n59_TQ3Gn3H"
      },
      "source": [
        "## LSTM Autoencoder with 3 Latent Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxZpZfDaGvtP",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(latent_dim=3).to(device)\n",
        "decoder = Decoder(latent_dim=3).to(device)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX2Ap7nZGvtP",
        "outputId": "30affe1c-f31f-4c6c-f399-109596bbebcb",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgmfsZSoeGsd"
      },
      "source": [
        "### Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkRnYS7YGvtP",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "train_iterator = torch.utils.data.DataLoader(\n",
        "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMtpC-SGeGsd"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA-7waBrGvtP",
        "outputId": "e56510c0-e0e9-4776-aca5-f6c732ce4d0f",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "random_seed(seed=42)\n",
        "\n",
        "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS0k7someGsd"
      },
      "source": [
        "### Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx6HnYjSGvtP",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "5RZYrA-tGvtP",
        "outputId": "69bedb4b-2385-4e43-a530-34443399fae4",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "embeddings(encode, shape_=image.shape[0:2], figsize=(10, 5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "GJ86cQiXGYzE",
        "outputId": "c8047b8f-9d40-4580-f835-949c01382fca",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
        "                 figsize=(10, 5), divider_=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_giijefIzF2"
      },
      "source": [
        "- This once again is very hard to interpret and the spectra do not really contain the necessary details\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMyxBetpJamg"
      },
      "source": [
        "## Disentanglement\n",
        "\n",
        "### Regularization\n",
        "\n",
        "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/L1_reg.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHkc_xwIeGsd"
      },
      "source": [
        "### Builds the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSX_7SdDJaGl",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "latent_dim = 12\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=12):\n",
        "        self.latent_dim = latent_dim\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(1, 12, batch_first=True, bidirectional=True)\n",
        "        self.embedding = nn.Linear(24, self.latent_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (_, __) = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.embedding(x)\n",
        "        x = self.relu(x)  # add a relu\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=12):\n",
        "        self.latent_dim = latent_dim\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(self.latent_dim, 12,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.tdd = nn.Conv1d(24, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[:, :, None]\n",
        "        x = x.transpose(1, 2)\n",
        "        x = x.repeat([1, 10, 1])\n",
        "        x, (_, __) = self.lstm(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.tdd(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORlK3DY5KBv8",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGJe2VxWKBv8",
        "outputId": "2765c9b8-9206-458f-f126-4d1ed18b992b",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFWbUSgeeGsd"
      },
      "source": [
        "### Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkm3Tc1KKBv9",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "train_iterator = torch.utils.data.DataLoader(\n",
        "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ICzubVheGsd"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U54m0q8yKBv9",
        "outputId": "c7899656-859a-4461-c8a3-b86e4d326aa2",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "random_seed(seed=42)\n",
        "\n",
        "Train(\n",
        "    model,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    train_iterator,\n",
        "    optimizer,\n",
        "    500,\n",
        "    coef=1e-3, # adds a regularization term l1\n",
        "    mse=False,\n",
        "    device=device,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt0ivOvmeGsd"
      },
      "source": [
        "### Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLDkYlnAKBv-",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "7o9IYLppKBv-",
        "outputId": "1be09e38-92c9-4265-d377-dc2e52288d2b",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "embeddings(encode, shape_=image.shape[0:2], figsize=(15, 5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "iCzmhDLhDweA",
        "outputId": "ead47227-7af1-4603-9f59-bfb80175def9",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
        "                 figsize=(5, 2.5), divider_=False, indx=[2, 8, 9])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "P37ZL7fbDhNY",
        "outputId": "c626eacd-6288-4b75-92e5-08d955e17c3c",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "fig, ax = layout_fig(6, mod=3)\n",
        "\n",
        "ax = ax.ravel()\n",
        "\n",
        "cmap = plt.cm.viridis\n",
        "\n",
        "for i, ax in enumerate(ax):\n",
        "    if i < 3:\n",
        "        img = np.zeros(image.shape)\n",
        "        img[:, :, i] = image[:, :, i]\n",
        "        ax.imshow(img)\n",
        "    else:\n",
        "        values = np.zeros((5, 3))\n",
        "        values[:, i - 3] = np.linspace(0, 1, 5)\n",
        "        y_data = generate_data(values, length=10)\n",
        "        for j in range(y_data.shape[0]):\n",
        "            color = cmap((j + 1) / y_data.shape[0])\n",
        "            ax.plot(y_data[j], c=color)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziD-a9wCtHd5"
      },
      "source": [
        "## Attention Mechanisms\n",
        "\n",
        "\n",
        "\n",
        "Builds the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGb8Oat_tHd6",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "latent_dim = 12\n",
        "seq_len = 10\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                             -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, latent_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(latent_dim, num_heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(latent_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(latent_dim, latent_dim * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim * 2, latent_dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out, _ = self.attn(x, x, x)\n",
        "        x = self.norm1(x + attn_out)\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm2(x + ff_out)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=12, num_layers=3):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_proj = nn.Linear(1, latent_dim)\n",
        "        self.pos_encoder = PositionalEncoding(latent_dim)\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(latent_dim, num_heads=2) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.embedding = nn.Linear(latent_dim, latent_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)           # (B, T, latent_dim)\n",
        "        x = self.pos_encoder(x)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "        x = x[:, -1, :]                  # Use final token\n",
        "        x = self.relu(self.embedding(x))\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=12, seq_len=10, num_layers=3):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.expand = nn.Linear(latent_dim, latent_dim * seq_len)\n",
        "        self.pos_encoder = PositionalEncoding(latent_dim)\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(latent_dim, num_heads=2) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.output_proj = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, 1, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.expand(x).view(x.size(0), self.seq_len, -1)\n",
        "        x = self.pos_encoder(x)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.output_proj(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awo6fWZ4tHd6",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0dPz0jCtHd6",
        "outputId": "8c8c22b7-4097-4f91-f1bd-185d3dc4684f",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJcibmM1tHd6"
      },
      "source": [
        "### Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOFKz5ZctHd7",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "train_iterator = torch.utils.data.DataLoader(\n",
        "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUi-bsmetHd7"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NOu8CgntHd7",
        "outputId": "8c51d9c3-94a2-417b-f1b7-247f7f3732b6",
        "tags": [
          "hide-output",
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "random_seed(seed=42)\n",
        "\n",
        "Train(\n",
        "    model,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    train_iterator,\n",
        "    optimizer,\n",
        "    500,\n",
        "    coef=1e-4, # adds a regularization term l1\n",
        "    mse=False,\n",
        "    device=device,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q47zPuj3tHd7"
      },
      "source": [
        "### Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfOoX4XMtHd7",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "7LVtXfmrtHd7",
        "outputId": "e3c53250-b1e0-46ee-9a71-c4ce33df2c87",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "embeddings(encode, shape_=image.shape[0:2], figsize=(15, 5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "gTSHf6Z_tHd7",
        "outputId": "6e2cf91c-fc8e-4d2f-e6a3-a2030781a600",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
        "                 figsize=(5, 2.5), divider_=False, indx=[0, 1, 5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "2G9ZYMt3tHd7",
        "outputId": "c9eacb23-d2d9-4e2f-aea8-42425d5f6a16",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "fig, ax = layout_fig(6, mod=3)\n",
        "\n",
        "ax = ax.ravel()\n",
        "\n",
        "cmap = plt.cm.viridis\n",
        "\n",
        "for i, ax in enumerate(ax):\n",
        "    if i < 3:\n",
        "        img = np.zeros(image.shape)\n",
        "        img[:, :, i] = image[:, :, i]\n",
        "        ax.imshow(img)\n",
        "    else:\n",
        "        values = np.zeros((5, 3))\n",
        "        values[:, i - 3] = np.linspace(0, 1, 5)\n",
        "        y_data = generate_data(values, length=10)\n",
        "        for j in range(y_data.shape[0]):\n",
        "            color = cmap((j + 1) / y_data.shape[0])\n",
        "            ax.plot(y_data[j], c=color)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2wvG-Vpv8Up"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Tags",
    "colab": {
      "machine_shape": "hm",
      "name": "Autoencoder Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "isaf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
