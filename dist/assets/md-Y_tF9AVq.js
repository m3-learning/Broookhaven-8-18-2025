import{aJ as l,b as p,o as r,w as i,ah as c,f,g as t,ad as s,v as d,x as u,T as o}from"./modules/vue-D0O7rk7U.js";import{_}from"./ncolumns-B_TQ8vhx.js";import{u as x,f as g}from"./slidev/context-BBkRYvY8.js";import"./SlideNumber-BjfYwgdJ.js";import"./index-DxexVWbq.js";import"./modules/shiki-XsCVdVtb.js";const v={class:"text-left",style:{"font-size":"0.9rem !important","line-height":"1.25","font-family":"Arial, sans-serif"}},N={__name:"attention_map.md__slidev_22",setup(y){const{$clicksContext:a,$frontmatter:n}=x();return a.setup(),(h,e)=>{const m=l("click");return r(),p(_,d(u(o(g)(o(n),21))),{"col0-text":i(()=>e[0]||(e[0]=[t("div",{class:"text-center text-sm"},' Attention maps from ResNet-50 and XCiT models on "p4" symmetry inputs. ',-1)])),text:i(()=>[c((r(),f("div",v,e[1]||(e[1]=[t("b",null,"(a, f)",-1),s(' Representative input images exhibiting "p4" symmetry. '),t("b",null,"(b–e)",-1),s(" Attention maps extracted from successive layers of the ResNet-50 model, illustrating the progression from early to deep representations. "),t("b",null,"(g–j)",-1),s(" Attention maps generated by the XCiT model from early to deep layers, highlighting differences in feature focus. ")]))),[[m,1]])]),_:1},16)}}};export{N as default};
